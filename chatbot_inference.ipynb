{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b70692c8-e9f5-4b1a-b1f4-47619324d842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c04c3b5e7149e18815d10c212301db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# ft = '/mnt/opt/alexw/zjkarina/gpt-j-onlyk_v2'\n",
    "ft = 'zjkarina/ChatGPTJ_6B'\n",
    "tokenizer_dialog = AutoTokenizer.from_pretrained(ft)\n",
    "model_dialog = AutoModelForCausalLM.from_pretrained(ft, torch_dtype=torch.float16, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ca6f253-4475-4389-a561-583a78d84564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(55083, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=55083, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForPreTraining, AutoTokenizer, BertTokenizer\n",
    "import torch\n",
    "tokenizer_sbert = BertTokenizer.from_pretrained(\"zjkarina/LaBSE-instructDialogs\")\n",
    "print(tokenizer_sbert.vocab_size)\n",
    "model_sbert = AutoModelForPreTraining.from_pretrained(\"zjkarina/LaBSE-instructDialogs\")\n",
    "model_sbert.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad8e3397-d609-4b62-bb1d-2727a600afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\n",
    "        \"max_new_tokens\": 100,\n",
    "        \"top_k\": 70,\n",
    "        \"top_p\": 0.8,\n",
    "        \"do_sample\": True,  \n",
    "        \"no_repeat_ngram_size\": 2,\n",
    "        \"bos_token_id\": tokenizer_dialog.bos_token_id,\n",
    "        \"eos_token_id\": tokenizer_dialog.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer_dialog.pad_token_id,\n",
    "        \"temperature\": 0.8,\n",
    "        \"use_cache\": True,\n",
    "        \"repetition_penalty\": 1.2,\n",
    "        \"num_return_sequences\": 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7b468d-2450-47d9-9f8c-41a88d2616d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTJForCausalLM(\n",
       "  (transformer): GPTJModel(\n",
       "    (wte): Embedding(50400, 4096)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-27): 28 x GPTJBlock(\n",
       "        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTJAttention(\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): GPTJMLP(\n",
       "          (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dialog.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ba265e0-8bd9-45bb-90de-c0c81a25ae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the name of the bot Jim\n",
      "Enter the facts about bot likes coffee, going for a walk, student\n",
      "Enter the your name Karina\n",
      "Enter facts about yourself programmer, likes cats\n"
     ]
    }
   ],
   "source": [
    "bot_name = input('Enter the name of the bot')\n",
    "bot_facts = input('Enter the facts about bot')\n",
    "human_name = input('Enter the your name')\n",
    "human_facts = input('Enter facts about yourself')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4520c10d-0a1d-4716-8c07-d9019bad1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "how would you like to see the behavior of the chatbot:  nice, interesting speaker, active\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "key_senntence = input('how would you like to see the behavior of the chatbot: ')\n",
    "encoded_key = tokenizer_sbert(key_senntence, padding=True, truncation=True, max_length=24, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    model_out_key = model_sbert.bert(**encoded_key.to('cuda'))\n",
    "key_senntence_embeddings = torch.nn.functional.normalize(model_out_key.pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27d89348-3f4e-484a-bf7d-ef46c0cc9351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Karina: hi, how are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim: I'm doing well. How about you, what's your name and do you like any hobbies or interests?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Karina: My name is Karina, I like coding, what about you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim: Nice to meet you! So, can we chat more about our favorite programming languages and websites? What kind of things do they inspire you to create?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Karina: My favorite programming language is python, what do you like?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim: Python too! It has such an intuitive syntax that makes it easy to learn. And the community around it is amazing. Have you ever worked with other developers before?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Karina: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim: Yes, actually. One time I was working on a project with some friends from college, and one day we had a breakthrough moment where everything just clicked into place. It felt so empowering. Do you have any similar experiences?\n"
     ]
    }
   ],
   "source": [
    "persons = f'{bot_name}, who is {bot_facts} talks to {human_name}, who is {human_facts}'\n",
    "history = []\n",
    "request = ''\n",
    "while request != 'stop':\n",
    "    request = input(f'{human_name}:')\n",
    "    to_history = ' <|endoftext|> ' + human_name + ': ' + request + ' <|endoftext|> ' + bot_name + ': '\n",
    "    all_dialog = persons + ' <|endoftext|> ' + ''.join(history) + to_history\n",
    "    input_ids = tokenizer_dialog.encode(all_dialog, return_tensors='pt').to(model_dialog.device)\n",
    "    options = []\n",
    "    for i in range(3): \n",
    "        generated = model_dialog.generate(input_ids=input_ids, **gen_kwargs)\n",
    "        response = tokenizer_dialog.batch_decode(generated[:, len(input_ids[0]):], skip_special_tokens=True)\n",
    "        options.append(response[0])\n",
    "    encoded_input = tokenizer_sbert(options, padding=True, truncation=True, max_length=64, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        model_output = model_sbert.bert(**encoded_input.to('cuda'))\n",
    "    embeddings = model_output.pooler_output\n",
    "    embeddings = torch.nn.functional.normalize(embeddings)\n",
    "    cos_similarities = util.cos_sim(key_senntence_embeddings, embeddings)[0]\n",
    "    most_sim = options[cos_similarities.argmax()]\n",
    "    print(f'{bot_name}:{most_sim}')\n",
    "    history.append(to_history)\n",
    "    history.append(response[0])\n",
    "    if len(history) < 12:\n",
    "        history = history[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c23da-758f-4734-91fb-8f3afe9f18d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
