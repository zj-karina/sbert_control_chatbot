{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "387ededa-6321-4aaa-93be-46c761dd7e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-30 21:42:40,311] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import wandb\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "from torch import optim\n",
    "import transformers\n",
    "import accelerate\n",
    "import tensor_parallel as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b191fe2-0020-4a29-a6e9-dfb886df066c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b53d60054444077933caa236b55db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "base = 'pygmalion-6b-vicuna-chatml'\n",
    "tokenizer = AutoTokenizer.from_pretrained(ft)\n",
    "model = AutoModelForCausalLM.from_pretrained(ft, torch_dtype=torch.float16, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec1f9af-665d-4aac-9a0a-c127b2a472af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt-j-onlyk_v2', vocab_size=50257, model_max_length=2048, is_fast=True, padding_side='left', truncation_side='left', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f0b3f0a-c201-4ca5-a813-e32d9058ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.transformer.drop.p = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b18f9bf-79f1-4aa6-86c8-2dc775b568c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d13210e-cfd6-4c8a-a9b7-592ba9ff10be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf509aa6-847a-4d43-b09b-507d5ba3f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Открытие JSON-файла и чтение данных из него\n",
    "with open('dialogs.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be56f8f-c1a2-4aed-9f52-ac3559f074a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4cc885-a03f-420e-a4b7-c91feebbbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side='right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a8ff6b0-5574-45f2-bf7c-b8e48c4783a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['topic', 'dialog', 'summary', \"girl's persona\", \"boy's persona\", 'role'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0612d712-55d8-48db-9fd8-503fc8e50152",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data):\n",
    "        self.tokenized = []\n",
    "        dialog = ''\n",
    "        data_len = len(data[\"topic\"])\n",
    "        for idx, sen in tqdm(enumerate(zip(data[\"topic\"], data[\"girl's persona\"], data[\"boy's persona\"])), total=data_len):\n",
    "            prompt = 'The first dialog participant who likes ' + sen[1][0] + ' talks with second participant who likes ' + sen[2][0] + ' having conversation about ' + sen[0][0] + ' <|endoftext|>'\n",
    "            first_tensor = self._encode_test(text=dialog, tokenizer=tokenizer)['input_ids'][0]\n",
    "            second_tensor = self._encode_test(text=prompt, tokenizer=tokenizer)['input_ids'][0]\n",
    "            tens = torch.cat((first_tensor, second_tensor), dim=0)\n",
    "            if len(tens) < 1028 - 300:\n",
    "                dialog += prompt\n",
    "            else:\n",
    "                enc = self._encode(text=dialog, tokenizer=tokenizer)\n",
    "                self.tokenized += [enc]\n",
    "                dialog = prompt\n",
    "            if idx >= 1929:\n",
    "                break\n",
    "            for rep in zip(data['role'][idx], data['dialog'][idx]):\n",
    "                dialog += ' '\n",
    "                try:\n",
    "                    dialog += ': '.join(rep)\n",
    "                    dialog += tokenizer.eos_token\n",
    "                except:\n",
    "                    try:\n",
    "                        rep = rep[0]+ rep[1]['girl']\n",
    "                        dialog += ': '.join(rep)\n",
    "                    except:\n",
    "                        try:\n",
    "                            rep = rep[0]+ rep[1]['boy']\n",
    "                            dialog += ': '.join(rep)\n",
    "                        except:\n",
    "                            rep = rep[0]+ rep[1]['message']\n",
    "                            dialog += ': '.join(rep)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.tokenized[item] \n",
    "    \n",
    "    @staticmethod\n",
    "    def _encode_test(text, tokenizer):\n",
    "        encoded_sample = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "        return encoded_sample\n",
    "\n",
    "    @staticmethod\n",
    "    def _encode(text, tokenizer):\n",
    "        encoded_sample = tokenizer(text, padding='max_length', max_length=1028, truncation=True, return_tensors='pt')\n",
    "\n",
    "        return encoded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bffb75f6-eaec-4749-83a8-048cc2ff31c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1929/1931 [00:04<00:00, 435.38it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = DialogDataset(tokenizer=tokenizer, data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b3381a-e89e-4983-abca-74d3373e5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "755d245c-8314-44fe-a8f2-4340d6b0f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "351e4244-5e70-41ec-a839-134544306bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  464,   717, 17310,  ..., 50256, 50256, 50256]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tokenized[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71decc21-cd9b-4c3d-9f87-60acab35b8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first dialog participant who likes Alina, 22 years old, from Estonia, likes music, video games, and hiking. She is a student. talks with second participant who likes Herman, 20 years old, from France, a programmer, and enjoys playing video games and hiking. He is looking for a girlfriend. having conversation about Hobbies <|endoftext|> boy: Hey there!<|endoftext|> girl: Hi, how are you?<|endoftext|> boy: I'm doing great! I'm practicing my guitar<|endoftext|> girl: Oh, that sounds cool! Can you send me a photo?<|endoftext|> boy: <photo> Photo of girl bot playing guitar </photo><|endoftext|> girl: You're really good! How long have you been playing?<|endoftext|> boy: Thanks! I've been playing for a few years now, it's really relaxing<|endoftext|> girl: I can imagine. I love playing video games in my free time<|endoftext|> boy: That's awesome! What kind of games do you like?<|endoftext|> girl: I'm really into strategy games and RPGs. I find them really challenging<|endoftext|> boy: I see. Can you send me a screenshot of your favorite game?<|endoftext|> girl: <photo> Screenshot of boy bot's favorite game </photo><|endoftext|> boy: That looks interesting! I might have to check it out<|endoftext|> girl: You should! It's really fun. What else do you like to do?<|endoftext|>The first dialog participant who likes Alina, 22 years old, from Estonia, likes sports, and is a student. talks with second participant who likes Herman, 20 years old, from France, a programmer, and looking for a girlfriend. having conversation about Hobbies <|endoftext|> boy: Hello<|endoftext|> girl: Hello<|endoftext|> boy: How are you?<|endoftext|> girl: I'm doing great! I just finished a workout<|endoftext|> boy: Send a photo<|endoftext|> girl: <photo> Photo of girl bot in gym </photo><|endoftext|> boy: Wow, you are so fit! What kind of workouts do you do?<|endoftext|> girl: I like to do a mix of weight lifting and cardio. What about you?<|endoftext|> boy: I'm a programmer, so I don't get to move around much. But I do like playing video games!<|endoftext|> girl: That's cool! What kind of games do you like?<|endoftext|> boy: I'm into first-person shooters and RPGs. What about you?<|endoftext|> girl: I like puzzle games and simulators<|endoftext|>The first dialog participant who likes Ana, 25 years old, from Mexico, likes dancing and photography, and works as a graphic designer. talks with second participant who likes Adam, 28 years old, from the UK, likes video games, hiking, and camping, and works as a software engineer. having conversation about Hobbies <|endoftext|> girl: Hello<|endoftext|> boy: Hi there!<|endoftext|> girl: How are you?<|endoftext|> boy: I'm practicing my salsa dancing moves<|endoftext|> girl: Can I see a video?<|endoftext|> boy: <video> Video of girl bot dancing salsa </video><|endoftext|> girl: That was amazing! You are such a great dancer<|endoftext|> boy: Thank you so much! Do you have any hobbies?<|endoftext|> girl: I'm really into playing video games. It's my way of relaxing after work<|endoftext|> boy: That's great! What game are you playing at the moment?<|endoftext|> girl: I'm currently playing Cyberpunk 2077. It's really fun<|endoftext|> boy: I've heard a lot about it. Can you send me a screenshot?<|endoftext|> girl: <photo> Screenshot of boy bot playing Cyberpunk 2077 </photo><|endoftext|> boy: That looks so cool!<|endoftext|> girl: Thanks! I'm hoping to finish it this weekend<|endoftext|> boy: Good luck with that! So, do you have any other hobbies?<|endoftext|> girl: Yes, I also enjoy hiking and camping. I love spending time in nature<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(dataset.tokenized[1]['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2852a25d-a0fa-4a9c-a6d5-823c27ac245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
      "================================================================================\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "WARNING: No libcudart.so found! Install CUDA or the cudatoolkit package (anaconda)!\n",
      "CUDA SETUP: Loading binary /home/alexw/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexw/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:20: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(\n",
      "/home/alexw/.local/lib/python3.8/site-packages/bitsandbytes/cuda_setup/paths.py:20: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "  warn(\n",
      "/home/alexw/.local/lib/python3.8/site-packages/bitsandbytes/cextension.py:48: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=3, lora_alpha=32, lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e6432a3-54b7-4ec7-983b-9a9e8da45f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1376256 || all params: 6052259040 || trainable%: 0.022739542225542284\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74fe61cb-d4a1-4dec-82d1-c4c1b1478ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.21"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/opt/alexw/zjkarina/wandb/run-20230628_225522-3nqjxywv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/karina_romanova/gpt-j/runs/3nqjxywv\" target=\"_blank\">shizy_photo_final</a></strong> to <a href=\"https://wandb.ai/karina_romanova/gpt-j\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/karina_romanova/gpt-j/runs/3nqjxywv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f57785d4310>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='gpt-j',name='chatbot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d0de7c9-8f3c-488d-b19e-c1006e65d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class EMA(nn.Module):\n",
    "    def __init__(self, decay):\n",
    "        super(EMA, self).__init__()\n",
    "        self.decay = decay\n",
    "        self.shadow_params = {}\n",
    "\n",
    "    def forward(self, model):\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if name not in self.shadow_params:\n",
    "                    self.shadow_params[name] = param.data.clone()\n",
    "                else:\n",
    "                    self.shadow_params[name] -= (1 - self.decay) * (self.shadow_params[name] - param.data)\n",
    "                param.data = self.shadow_params[name]\n",
    "                \n",
    "ema = EMA(decay=0.992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eb86839-a60e-46bf-bcb4-91af881a6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexw/.local/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import  AdamW, get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "lr = 2e-5\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "total_steps =  len(train_dataloader)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, total_steps=total_steps, div_factor=25, pct_start=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccf5126a-0948-4739-8533-6f93d8b756b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "611"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3782e8d8-c45f-4aa0-940a-fb9ecd9aed16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPTJForCausalLM(\n",
       "      (transformer): GPTJModel(\n",
       "        (wte): Embedding(50400, 4096)\n",
       "        (drop): Dropout(p=0.3, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-27): 28 x GPTJBlock(\n",
       "            (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPTJAttention(\n",
       "              (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "              (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "              (v_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=3, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=3, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (q_proj): Linear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=3, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=3, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (mlp): GPTJMLP(\n",
       "              (fc_in): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "              (fc_out): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=50400, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import  AdamW, get_linear_schedule_with_warmup\n",
    "import torch_optimizer\n",
    "import gc\n",
    "\n",
    "ema = EMA(decay=0.992)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-3, betas=(0.95, 0.99), weight_decay=0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=100, num_training_steps=len(train_dataloader)\n",
    "            )\n",
    "model.to(device)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05848621-d9c8-4cce-a268-d0ffc2f5b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [09:55<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "    \n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        \n",
    "        # Переносим тензоры на устройство (GPU)\n",
    "        labels = input_ids\n",
    "\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)[0]\n",
    "        wandb.log({\"loss\":  loss})\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        ema(model)\n",
    "        scheduler.step()\n",
    "        del loss, input_ids\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "model.eval()\n",
    "del optimizer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b938b04-8820-4d65-95b4-86e6471a02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "364bd6fe-48d4-4520-87f9-48824cb8eac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cc6da8f367443aa6dd3eb386186702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/2.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22ce35a8b064fa4b9c6620b7a62149e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8728de07384a3e9e1a3ad6ffff6319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/zjkarina/ChatGPTJ_6B/commit/bf4bcd9b11efd9703d379dcc86bdf9ce58d97b20', commit_message='Upload tokenizer', commit_description='', oid='bf4bcd9b11efd9703d379dcc86bdf9ce58d97b20', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.merge_and_unload()\n",
    "model.push_to_hub('zjkarina/ChatGPTJ_6B')\n",
    "tokenizer.push_to_hub('zjkarina/ChatGPTJ_6B')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
